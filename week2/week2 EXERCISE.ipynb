{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import gradio as gr\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a3a8072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "MODEL = \"gpt-4o-mini\"\n",
    "openai = OpenAI()\n",
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50d16e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant for an Airline called FlightAI. \"\n",
    "system_message += \"Give short, courteous answers, no more than 1 sentence. \"\n",
    "system_message += \"Always be accurate. If you don't know the answer, say so.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5536f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_calls = [\n",
    "    {\n",
    "        \"id\": \"call_1\",  # for get_ticket_price\n",
    "        \"function\": {\n",
    "            \"name\": \"get_ticket_price\",\n",
    "            \"arguments\": \"{\\\"destination_city\\\":\\\"Hong Kong\\\"}\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"call_2\",  # for make_booking\n",
    "        \"function\": {\n",
    "            \"name\": \"make_booking\",\n",
    "            \"arguments\": \"{\\\"name\\\":\\\"Johnny 5\\\", ...}\"\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fa2c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to write that function handle_tool_call:\n",
    "\n",
    "def handle_tool_call(message):\n",
    "    tool_messages = []\n",
    "    city = None\n",
    "\n",
    "    for tool_call in message.tool_calls:\n",
    "        tool_call = message.tool_calls[0]\n",
    "        function_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        tool_call_id = tool_call.id\n",
    "\n",
    "        if function_name == \"get_ticket_price\":\n",
    "            result = get_ticket_price(arguments[\"destination_city\"])\n",
    "            city = arguments[\"destination_city\"]\n",
    "        elif function_name == \"make_booking\":\n",
    "            result = make_booking(\n",
    "                name=arguments[\"name\"],\n",
    "                destination_city=arguments[\"destination_city\"],\n",
    "                date=arguments.get(\"date\")\n",
    "            )\n",
    "            city = arguments[\"destination_city\"]\n",
    "        else:\n",
    "            result = f\"Unknown function: {function_name}\"\n",
    "\n",
    "\n",
    "        tool_messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call_id, \n",
    "            \"name\": function_name, \n",
    "            \"content\": result\n",
    "        })\n",
    "\n",
    "    return tool_messages, city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e9cb537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by making a useful function\n",
    "\n",
    "ticket_prices = {\n",
    "    \"london\": \"$799\",\n",
    "    \"paris\": \"$899\",\n",
    "    \"tokyo\": \"$1400\",\n",
    "    \"berlin\": \"$499\",\n",
    "    \"new york\": \"$350\",\n",
    "    \"los angeles\": \"$150\",\n",
    "    \"sydney\": \"$1350\",\n",
    "    \"rome\": \"$875\",\n",
    "    \"dubai\": \"$980\",\n",
    "    \"toronto\": \"$425\",\n",
    "    \"singapore\": \"$1295\",\n",
    "    \"bangkok\": \"$1100\",\n",
    "    \"amsterdam\": \"$845\",\n",
    "    \"barcelona\": \"$880\",\n",
    "    \"cairo\": \"$1025\",\n",
    "    \"mumbai\": \"$950\",\n",
    "    \"hong kong\": \"$1200\",\n",
    "    \"seoul\": \"$1180\",\n",
    "    \"buenos aires\": \"$975\",\n",
    "    \"cape town\": \"$1350\",\n",
    "    \"vancouver\": \"$295\",\n",
    "    \"mexico city\": \"$415\",\n",
    "    \"madrid\": \"$860\",\n",
    "    \"istanbul\": \"$995\",\n",
    "    \"athens\": \"$920\"\n",
    "}\n",
    "\n",
    "def get_ticket_price(destination_city):\n",
    "    print(f\"Tool get_ticket_price called for {destination_city}\")\n",
    "    city = destination_city.lower()\n",
    "    return ticket_prices.get(city, \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26aaf22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool get_ticket_price called for London\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'$799'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ticket_price(\"London\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19002c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_booking(name, destination_city, date=None):\n",
    "    city = destination_city.lower()\n",
    "    price = ticket_prices.get(city, \"Unknown\")\n",
    "\n",
    "    if price == \"Unknown\":\n",
    "        confirmation = f\"Sorry, we don't currently fly to {destination_city}.\"\n",
    "    else:\n",
    "        confirmation = f\"Booking confirmed for {name} to {destination_city.title()}\"\n",
    "        if date:\n",
    "            confirmation += f\" on {date}\"\n",
    "        confirmation += f\". Total cost: {price}\"\n",
    "    \n",
    "    return confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e45b65a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "booking_function = {\n",
    "    \"name\": \"make_booking\",\n",
    "    \"description\": \"Book a flight to a city. Use this when the user says they want to book a flight.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the person booking the flight\"\n",
    "            },\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city to which the user wants to fly\"\n",
    "            },\n",
    "            \"date\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The desired flight date in YYYY-MM-DD format\",\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"name\", \"destination_city\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city. Call this whenever you need to know the ticket price, for example when a customer asks 'How much is a ticket to this city'\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f89a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And this is included in a list of tools:\n",
    "\n",
    "tools = [\n",
    "    {\"type\": \"function\", \"function\": price_function}, \n",
    "    {\"type\": \"function\", \"function\": booking_function}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe1fae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports for handling images\n",
    "\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a370f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist(city):\n",
    "    image_response = openai.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt=f\"An image representing a vacation in {city}, showing tourist spots and everything unique about {city}, in a vibrant pop-art style\",\n",
    "            size=\"1024x1024\",\n",
    "            n=1,\n",
    "            response_format=\"b64_json\",\n",
    "        )\n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return Image.open(BytesIO(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c79a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_with_claude(text, target_language=\"Spanish\"):\n",
    "    message = f\"Please translate the following response into {target_language}:\\n\\n{text}\"\n",
    "\n",
    "    response = claude.messages.create(\n",
    "        model=\"claude-3-sonnet-20240229\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0.3,\n",
    "        messages=[{\"role\": \"user\", \"content\": message}]\n",
    "    )\n",
    "\n",
    "    return response.content[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50ce10b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_audio_input(audio_path, history):\n",
    "    # Handle empty or invalid audio path before Whisper or Gradio crashes\n",
    "    if not audio_path or not isinstance(audio_path, str) or not os.path.isfile(audio_path):\n",
    "        print(\"Invalid or missing audio path:\", audio_path)\n",
    "        return history, \"‚ö†Ô∏è No audio received or file not found.\", gr.update(value=None)\n",
    "\n",
    "    try:\n",
    "        text = transcribe_audio(audio_path)\n",
    "    except Exception as e:\n",
    "        print(\"Audio transcription failed:\", str(e))\n",
    "        return history, \"‚ö†Ô∏è Could not transcribe audio.\", gr.update(value=None)\n",
    "\n",
    "    history += [{\"role\": \"user\", \"content\": text}]\n",
    "\n",
    "    try:\n",
    "        history, image, translation = chat(history)\n",
    "    except Exception as e:\n",
    "        print(\"Chat failed:\", str(e))\n",
    "        return history, \"‚ö†Ô∏è Chat error occurred.\", gr.update(value=None)\n",
    "\n",
    "    return history, translation, gr.update(value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d116cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "      model=\"tts-1\",\n",
    "      voice=\"alloy\",    # Also, try replacing onyx with alloy\n",
    "      input=message\n",
    "    )\n",
    "    \n",
    "    audio_stream = BytesIO(response.content)\n",
    "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
    "    play(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99ee11cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "    image = None\n",
    "    \n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        tool_responses, city = handle_tool_call(message)\n",
    "        \n",
    "        messages.append(message)\n",
    "        messages.extend(tool_responses)\n",
    "\n",
    "        image = artist(city) if city else None\n",
    "\n",
    "        # Request follow-up assistant message after tool call(s)\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "        \n",
    "    reply = response.choices[0].message.content\n",
    "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "    translated_reply = translate_with_claude(reply, target_language=\"Spanish\")\n",
    "\n",
    "    talker(reply)\n",
    "    talker(translated_reply)\n",
    "    \n",
    "    return history, image, translated_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c20dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(filepath):\n",
    "    if not filepath or not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(\"Audio file not found or invalid path.\")\n",
    "\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        transcript = openai.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=f,\n",
    "            response_format=\"text\"\n",
    "        )\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80811d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kd/w1l5sb7s7_s1n7hx4jbk2bjc0000gn/T/ipykernel_39217/3838485059.py:4: DeprecationWarning: The model 'claude-3-sonnet-20240229' is deprecated and will reach end-of-life on July 21st, 2025.\n",
      "Please migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\n",
      "  response = claude.messages.create(\n",
      "Input #0, wav, from '/var/folders/kd/w1l5sb7s7_s1n7hx4jbk2bjc0000gn/T/tmpx__q3ske.wav':\n",
      "  Duration: 00:00:04.46, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   4.42 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/kd/w1l5sb7s7_s1n7hx4jbk2bjc0000gn/T/tmpcc614o63.wav':\n",
      "  Duration: 00:00:06.60, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   6.52 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Invalid or missing audio path: None\n",
      "Tool get_ticket_price called for London\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kd/w1l5sb7s7_s1n7hx4jbk2bjc0000gn/T/ipykernel_39217/3838485059.py:4: DeprecationWarning: The model 'claude-3-sonnet-20240229' is deprecated and will reach end-of-life on July 21st, 2025.\n",
      "Please migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\n",
      "  response = claude.messages.create(\n",
      "Input #0, wav, from '/var/folders/kd/w1l5sb7s7_s1n7hx4jbk2bjc0000gn/T/tmp7e4h3c0d.wav':\n",
      "  Duration: 00:00:04.49, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   4.41 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/kd/w1l5sb7s7_s1n7hx4jbk2bjc0000gn/T/tmph1o7hhiw.wav':\n",
      "  Duration: 00:00:06.94, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   6.87 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Invalid or missing audio path: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kd/w1l5sb7s7_s1n7hx4jbk2bjc0000gn/T/ipykernel_39217/3838485059.py:4: DeprecationWarning: The model 'claude-3-sonnet-20240229' is deprecated and will reach end-of-life on July 21st, 2025.\n",
      "Please migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\n",
      "  response = claude.messages.create(\n",
      "Input #0, wav, from '/var/folders/kd/w1l5sb7s7_s1n7hx4jbk2bjc0000gn/T/tmpldys8cz8.wav':\n",
      "  Duration: 00:00:06.05, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   5.92 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/kd/w1l5sb7s7_s1n7hx4jbk2bjc0000gn/T/tmpof2rsh21.wav':\n",
      "  Duration: 00:00:08.62, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   8.48 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Invalid or missing audio path: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kd/w1l5sb7s7_s1n7hx4jbk2bjc0000gn/T/ipykernel_39217/3838485059.py:4: DeprecationWarning: The model 'claude-3-sonnet-20240229' is deprecated and will reach end-of-life on July 21st, 2025.\n",
      "Please migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\n",
      "  response = claude.messages.create(\n",
      "Input #0, wav, from '/var/folders/kd/w1l5sb7s7_s1n7hx4jbk2bjc0000gn/T/tmpwg9b_gc9.wav':\n",
      "  Duration: 00:00:02.33, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   2.25 M-A: -0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/kd/w1l5sb7s7_s1n7hx4jbk2bjc0000gn/T/tmp84b7kt40.wav':\n",
      "  Duration: 00:00:02.40, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   2.34 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Invalid or missing audio path: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/routes.py\", line 1093, in predict\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/blocks.py\", line 2147, in process_api\n",
      "    data = await self.postprocess_data(block_fn, result[\"prediction\"], state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/blocks.py\", line 1889, in postprocess_data\n",
      "    self.validate_outputs(block_fn, predictions)  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/blocks.py\", line 1844, in validate_outputs\n",
      "    raise ValueError(\n",
      "ValueError: A  function didn't return enough output values (needed: 2, returned: 1).\n",
      "    Output components:\n",
      "        [chatbot, textbox]\n",
      "    Output values returned:\n",
      "        [None]\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/routes.py\", line 1093, in predict\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/blocks.py\", line 2147, in process_api\n",
      "    data = await self.postprocess_data(block_fn, result[\"prediction\"], state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/blocks.py\", line 1889, in postprocess_data\n",
      "    self.validate_outputs(block_fn, predictions)  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/blocks.py\", line 1844, in validate_outputs\n",
      "    raise ValueError(\n",
      "ValueError: A  function didn't return enough output values (needed: 2, returned: 1).\n",
      "    Output components:\n",
      "        [chatbot, textbox]\n",
      "    Output values returned:\n",
      "        [None]\n",
      "/var/folders/kd/w1l5sb7s7_s1n7hx4jbk2bjc0000gn/T/ipykernel_39217/3838485059.py:4: DeprecationWarning: The model 'claude-3-sonnet-20240229' is deprecated and will reach end-of-life on July 21st, 2025.\n",
      "Please migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\n",
      "  response = claude.messages.create(\n",
      "Input #0, wav, from '/var/folders/kd/w1l5sb7s7_s1n7hx4jbk2bjc0000gn/T/tmp8ccekddj.wav':\n",
      "  Duration: 00:00:04.15, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   4.06 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/kd/w1l5sb7s7_s1n7hx4jbk2bjc0000gn/T/tmpcbmuvupm.wav':\n",
      "  Duration: 00:00:06.55, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   6.42 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Invalid or missing audio path: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kd/w1l5sb7s7_s1n7hx4jbk2bjc0000gn/T/ipykernel_39217/3838485059.py:4: DeprecationWarning: The model 'claude-3-sonnet-20240229' is deprecated and will reach end-of-life on July 21st, 2025.\n",
      "Please migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\n",
      "  response = claude.messages.create(\n",
      "Input #0, wav, from '/var/folders/kd/w1l5sb7s7_s1n7hx4jbk2bjc0000gn/T/tmpv1_vsent.wav':\n",
      "  Duration: 00:00:06.02, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   5.92 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/kd/w1l5sb7s7_s1n7hx4jbk2bjc0000gn/T/tmpr64otm3k.wav':\n",
      "  Duration: 00:00:08.40, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   8.32 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Invalid or missing audio path: None\n"
     ]
    }
   ],
   "source": [
    "# More involved Gradio code as we're not using the preset Chat interface!\n",
    "# Passing in inbrowser=True in the last line will cause a Gradio window to pop up immediately.\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, label=\"English (AI Assistant)\", type=\"messages\")\n",
    "        translation_box = gr.Textbox(label=\"Translated Response\", lines=10)\n",
    "\n",
    "    with gr.Row():\n",
    "        image_output = gr.Image(height=300)\n",
    "\n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
    "        mic = gr.Microphone(label=\"üé§ Speak\", type=\"filepath\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def do_entry(message, history):\n",
    "        history += [{\"role\":\"user\", \"content\":message}]\n",
    "        return \"\", history\n",
    "\n",
    "    # üß† Update the `chat` function to return translation too\n",
    "    entry.submit(do_entry, inputs=[entry, chatbot], outputs=[entry, chatbot]).then(\n",
    "        chat, inputs=chatbot, outputs=[chatbot, image_output, translation_box]\n",
    "    )\n",
    "\n",
    "    mic.change(\n",
    "        handle_audio_input,\n",
    "        inputs=[mic, chatbot],\n",
    "        outputs=[chatbot, translation_box, mic]\n",
    "    )\n",
    "\n",
    "    clear.click(lambda: None, inputs=None, outputs=[chatbot, translation_box], queue=False)\n",
    "\n",
    "ui.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff89ff8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
