How to compare features of an LLM:
open or closed source
release date and knowledge cut off
parameters
training tokens
context length

inference cost (api charge)
training  costs
build cost
time to market
rate limits
speed
latency
license

Chincilla
-number of parameters proportional to number of training tokens

Benchmarks
ARC - reasoning
DROP - languare comp
HellaSwag - common sense
MMLU - understanding